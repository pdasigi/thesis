Natural Language Understanding (NLU) systems process human generated text (or speech) at a deep semantic level and encode the meaning
of the processed inputs. Several concrete tasks have been defined within the field on Computational Linguistics (CL) to evaluate the encoded meaning representations.
In the case of Semantic Parsing, the output is a logical form that can be queried against a knowledge base of facts to compute its truth value. Textual Entailment refers to the 
problem of identifying whether the truth of some text provided as a hypothesis follows from that of another text provided as a premise. Sentiment Analysis is the process of 
automatically categorizing the opinions expressed in the inputs towards specific targets. All these tasks require encoding the semantics of the input in a way that is
at least good enough to perform well at the given task, with the inherent assumption that an improvement in the task performance correlates with an improvement in the
quality of the semantic representation or in other words, the understanding capability of the computational system.
% TODO: Improve the following statement and uncomment it.
%Each task defines a restricted set of linguistic aspects that can be taught to a computational system, and are easy enough to automatically evaluate
%on unseen examples, but are complex enough for the representation techniques to be applicable to understanding the unrestricted set.

A generic NLU system can thus be succinctly described using the following two equations.
\begin{align}
 \mathbf{e} &= \mathtt{encode}(\mathbf{I}) \label{eq:generic_encoding}\\
 \mathbf{o} &= \mathtt{predict}(\mathbf{e}) \label{eq:generic_prediction}
\end{align}
where $\mathbf{I}$ is the set of textual inputs to the NLU system. 
%TODO: Concrete examples of systems that fit in this paradigm.
For example, $\mathbf{I}$  are single sentences in Sentiment Analysis and pairs of sentences in Textual Entailment. $\textbf{e}$ are intermediate 
encoded semantic representations of the inputs (which may or may not be task specific), and $\mathbf{o}$ are the final task specific predictions. For example, in Sentiment Analysis or Textual Entailment, 
$\mathbf{o}$ are categorical labels indicating the sentiment or entailment respectively, and in the case of Semantic Parsing, they are structured outputs or parses. In older feature-rich methods for NLU, 
Equation~\ref{eq:generic_encoding} is a mapping of the inputs to a hand designed feature space, typically containing patterns over word classes based on part-of-speech \cite{corley2005measuring} or Wordnet synsets \cite{moldovan2001logic} 
shallow linguistic features like dependencies \cite{bos2005recognising} or named entities \cite{tatu2005semantic}. In such systems,
the modeling emphasis was more on the prediction component, and the encoding component did not involve any learning. More recent systems \cite{weston2014memory,hermann2015teaching,Sukhbaatar2015EndToEndMN,Xiong2016DynamicMN} 
use representation learning techniques to also learn the parameters of the
$\mathtt{encode}$ function, and typically this is done jointly with learning the parameters of the $\mathtt{predict}$ function.

\section{External Knowledge}
\label{sec:intro_external_knowledge}
An issue with the formulation of the problem in Equation~\ref{eq:generic_encoding} and Equation~\ref{eq:generic_prediction} is that they are missing a key input: \textbf{contextual knowledge}. 
Since human language is aimed at other humans who share 
the same background knowledge, a lot of information is often not explicitly stated
for the sake of brevity. The implicit knowledge required to understand language varies 
from simple commonsense in the case of basic conversations, to complex principles that link 
concepts in more esoteric communications. Consider an example of the former in solving the 
textual entailment problem given the following premise, and a candidate hypothesis:
\begin{itemize}
 \item \textbf{Premise:} \textit{Children and parents are splashing water at the pool.}
 \item \textbf{Hypothesis} \textit{Families are playing outside.}
\end{itemize}
The knowledge a human uses to correctly predict that the hypothesis can be inferred from the 
premise is that \textit{children and parents} typically form \textit{families}, \textit{splashing water} 
is a kind of \textit{playing}, and a \textit{pool} is expected to be \textit{outside}. A different kind of knowledge 
is required by an  automated reading comprehension system that reads a science text book to answer the following 
question. It needs to reason about the question at hand given some relevant text on properties of materials.
\begin{itemize}
 \item \textit{Which of the following is the best conductor of electricity?}\\ 
  A. \textit{glass rod}  B. \textit{wooden stick}  C. \textit{plastic straw} D. \textit{metal nail}
\end{itemize}

Clearly, we need some external knowledge as an input to our NLU systems to perform well at tasks like this.
Without this additional context, the NLU systems will merely memorize specific patterns seen in the training data
and cannot generalize to unseen test cases. Accordingly, we modify our NLU equations as follows.
\begin{align}
 \mathbf{e} &= \mathtt{encode\_with\_knowledge}(\mathbf{I}, \mathbf{K}_e) \label{eq:encoding_with_knowledge}\\
 \mathbf{e}_{K_p} &= \mathtt{encode}(\mathbf{K}_p) \\ \label{eq:knowledge_encoding}
 \mathbf{o} &= \mathtt{predict\_with\_knowledge}(\mathbf{e}, \mathbf{e}_{K_p}) \label{eq:prediction_with_knowledge}
\end{align}
where $\mathbf{K}_e$ and $\mathbf{K}_p$ represent the knowledge required for encoding and prediction respectively. 
They serve different purposes as described below.

\subsection{Knowledge-aware encoding}
$\mathbf{K}_e$ is additional knowledge used to better compose the units in input text. Particularly, this allows for
obtaining input encoding that respects the selectional restrictions of the units being composed.
Examples of $\mathbf{K}_e$ include hypernym trees from WordNet for
incorporate commonsense information about concepts while composing sentences, and subgraph features from Freebase to encode relations
between entities seen in the input text. \cite{moldovan2001logic} is an examples of a feature-rich system that encoded input sentences in the 
context of external knowledge. Chapter~\ref{chapter:ontolstm} describes an representation-learning application of knowledge-aware encoding where 
we show the advantages of incorporating WordNet information in recurrent neural networks for encoding sentences. In addition to this application,
we propose a technique for encoding logical forms incorporating subgraph features from Freebase in Chapter~\ref{chapter:proposed_work}.

\subsection{Knowledge-aware reasoning}
$\textbf{K}_p$ inputs allow the prediction step to reason in the context of additional knowledge. Recent work in machine reading comprehension using 
attentive readers \cite{hermann2015teaching} and memory networks \cite{weston2014memory,Sukhbaatar2015EndToEndMN,Xiong2016DynamicMN} can be viewed as different instantiations
of the $\mathtt{predict\_with\_knowledge}$ function, where $\textbf{K}_p$ is some background text that needs to be understood to answer a question about it. 
In Chapter~\ref{chapter:memnet_qa}, we describe a generalized neural network formulation of reasoning in the context of background information,
and apply it to the problem of answering science questions.

\subsection{Issues with incorporating external knowledge}
Adding external knowledge inputs to NLU systems is not straightforward.  Firstly, while linking text being read to some structured knowledge
in a KB, an automated system faces ambiguity. For example, with lexical ontologies like WordNet, 
we get useful type hierarchies like \textit{parent is-a ancestor is-a person} and \textit{pool is-a body-of-water} 
and so on, but one has to deal with sense ambiguity: \textit{pool} can also be a game. Moreover, the fact that the two sources of semantic information are fundamentally different 
makes this challenging. While distributional approaches encode meaning in a
continuous and an abstract fashion, meaning in KBs is symbolic and discrete. A major chunk of this thesis will be dedicated to learning 
distributions over the discrete concepts of the KB conditioned on the context, to deal with exceptions in language.
When the external knowledge is used for reasoning, finding the 
relevant parts of the provided knowledge given the text being processed is a challenge. 
The goal of this thesis is to find the limitations of various knowledge sources -- structured and unstructured -- and use this information 
to build hybrid NLU systems that can successfully incorporate real world knowledge in deep learning models. We now describe how this thesis is organized.

\section{Outline}
% In the first part of this thesis, I will explore the limits of purely distributional models
% and study the kinds of information that cannot be modeled by them. A candidate problem for this
% exercise is semantic anomaly detection, which involves automatically 
% identifying real world commonsense violations in text. I shall describe an annotation
% effort that resulted in newswire headlines manually labeled with the degree
% of surprise associated with them. The task is to build a model that can identify the highly
% surprising headlines as anomalies. This is different from the usual Language Modeling (LM) problem
% because even the semantic anomalies are well-formed sentences that can be well-understood. Consequently,
% the model needs to discriminate between sentences at a semantic level deeper than surface fluency.
% I shall explore to what extent neural network language models (NNLM), the current state of the art in LM,
% are applicable in semantic anomaly detection. A popular technique used to avoid normalizing the probabilities
% over the entire vocabulary in NNLM is Noise Contrastive Estimation (NCE), which modifies the problem of 
% building a generative model into that of building a discriminative one to distinguish the data distribution
% from a predefined noise distribution. A challenge in building NNLM for semantic anomaly detection is that defining 
% the noise distribution in this case is not trivial. One way to address this challenge is to use ideas from 
% adversarial networks, where the noise samples themselves are generated by a neural network whose complexity
% is comparable to that of the network that discriminates the noise from the data. A baseline model for this 
% problem is a previously published supervised Recursive Neural Network trained for the same problem.

In Chapter~\ref{chapter:ontolstm}, we describe a method to incorporate selectional 
preferences in algorithms that encode sentences. This involves a variant of Long Short-Term
Memory (LSTM) based Recurrent Neural Networks (RNN) that use information
from WordNet, a lexical 
ontology. The hybrid model looks at WordNet synsets, and the hypernym hierarchies of the
words being processed so that the 
LSTM is aware of their different senses, and the corresponding type information.
The ontology aware LSTM (OntoLSTM) learns to attend to the appropriate sense,
and the relevant type 
(either the most specific concept or a generalization by choosing a hypernym of
the word), conditioned on the context and the end-objective. We show that the sentence representations 
produced by OntoLSTM are better than those produced by LSTMs when used with identical prediction 
components for predicting textual entailment. We also visualize the attention scores assigned to the hypernyms 
of words in the premises and hypotheses and show that OntoLSTM is indeed learning useful generalizations of words
that help the learned representations perform better at textual entailment.

In Chapter~\ref{chapter:memnet_qa} we describe a generalized deep learning architecture for knowledge guided reasoning.
The pipeline follows the generic specification in Section~\ref{sec:intro_external_knowledge} and has configurable components
for encoding and prediction. We identify that the memory network models in \cite{weston2014memory,Sukhbaatar2015EndToEndMN,Xiong2016DynamicMN}
and the attentive reader model from \cite{hermann2015teaching} are specific instantiations of our generic knowledge guided reasoning model.
Unlike prior work that evaluated these models on selecting answers from background text, we evaluate our model on answering science questions, 
a task that requires more reasoning capabilities.

Chapter~\ref{chapter:proposed_work} contains proposed work. Firstly, as an extension to the idea of knowledge augmented encoding, 
we propose incorporating probabilistic logic into our generic NLU pipeline. Particularly, we propose using from TensorLog \cite{cohen2016tensorlog},
a differentiable deductive database in models that recursively compose propositions in logical forms. Secondly, we propose methods to effectively evaluate NLU systems
and the role of external knowledge in them. In addition to evaluating the prediction accuracy, we propose to evaluate the encoding capability of the model by 
generating sentences in the input space using Encoder-Decoder models. To test the role of external knowledge, we will explore the limits of purely distributional models
and study the kinds of information that cannot be modeled by them. A candidate problem for this
exercise is semantic anomaly detection, which involves automatically 
identifying real world commonsense violations in text. We shall describe an annotation
effort that resulted in newswire headlines manually labeled with the degree
of surprise associated with them. The task is to build a model that can identify the highly
surprising headlines as anomalies. This is different from the usual Language Modeling (LM) problem
because even the semantic anomalies are well-formed sentences that can be well-understood. Consequently,
the model needs to discriminate between sentences at a semantic level deeper than surface fluency.
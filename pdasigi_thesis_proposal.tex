%for a more compact document, add the option openany to avoid
%starting all chapters on odd numbered pages
\documentclass[hidelinks,12pt]{cmuthesis}

% This is a template for a CMU thesis.  It is 18 pages without any content :-)
% The source for this is pulled from a variety of sources and people.
% Here's a partial list of people who may or may have not contributed:
%
%        bnoble   = Brian Noble
%        caruana  = Rich Caruana
%        colohan  = Chris Colohan
%        jab      = Justin Boyan
%        josullvn = Joseph O'Sullivan
%        jrs      = Jonathan Shewchuk
%        kosak    = Corey Kosak
%        mjz      = Matt Zekauskas (mattz@cs)
%        pdinda   = Peter Dinda
%        pfr      = Patrick Riley
%        dkoes = David Koes (me)

% My main contribution is putting everything into a single class files and small
% template since I prefer this to some complicated sprawling directory tree with
% makefiles.

% some useful packages
\usepackage{times}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{algorithm2e}
\usepackage{bbm}
\usepackage{multirow}
\usepackage{enumerate}
% \usepackage[numbers,sort]{natbib}
\usepackage[round]{natbib}
\usepackage[backref,pageanchor=true,plainpages=false, pdfpagelabels, bookmarks,bookmarksnumbered,
%pdfborder=0 0 0,  %removes outlines around hyper links in online display
]{hyperref}
\usepackage{subfigure}
\usepackage{cleveref}

\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\pred}[1]{{\fontfamily{qcr}\selectfont #1}}
\newcommand{\type}[1]{\ensuremath{\mathtt{#1}}}
\newcommand{\func}[2]{\ensuremath{\langle \type{#1},\type{#2} \rangle}}
\newcommand{\hole}[2]{\ensuremath{[\type{#1},#2]}} 

% Approximately 1" margins, more space on binding side
%\usepackage[letterpaper,twoside,vscale=.8,hscale=.75,nomarginpar]{geometry}
%for general printing (not binding)
\usepackage[letterpaper,twoside,vscale=.8,hscale=.75,nomarginpar,hmarginratio=1:1]{geometry}

% Provides a draft mark at the top of the document. 
\draftstamp{\today}{DRAFT}

\begin {document} 
\frontmatter

%initialize page style, so contents come out right (see bot) -mjz
\pagestyle{empty}

\title{ {\it \huge Thesis Proposal}\\
{\bf Knowledge-aware Natural Language Understanding}}
\author{Pradeep Dasigi}
\date{}
\Year{2017}
\trnumber{}

\committee{
Eduard Hovy (Chair) \\
Chris Dyer \\
William Cohen \\
Luke Zettlemoyer
}

\support{}
\disclaimer{}

% copyright notice generated automatically from Year and author.
% permission added if \permission{} given.

\keywords{natural language understanding, knowledge, neural networks, end-to-end models, semantic parsing, question answering}

\maketitle

% TODO: Uncomment this for the dissertation
% \begin{dedication}
% 
% \end{dedication}

\pagestyle{plain} % for toc, was empty

%% Obviously, it's probably a good idea to break the various sections of your thesis
%% into different files and input them into this file...

\begin{abstract}
Natural Language Understanding (NLU) systems need to encode human generated text (or speech) and reason over it at a deep semantic level.
Any NLU system typically involves two main components: The first is an \textbf{encoder}, which composes words (or other basic linguistic units) within the input utterances compute encoded representations, 
which are then used as features in the second component, a \textbf{predictor}, to reason over the encoded inputs and produce the desired output. We argue that the utterances themselves
do not contain all the information needed for understanding them and identify two kinds of additional knowledge needed to fill the gaps: 
\textbf{background knowledge} and \textbf{contextual knowledge}. The goal of this thesis is to build end-to-end NLU systems that encode inputs along with relevant
background knowledge, and reason about them in the presence of contextual knowledge.

The first part of the thesis deals with background knowledge. While distributional methods for encoding inputs have been
used to represent meaning of words in the context of other words in the input, there are other aspects of semantics that are out of their reach. These are related to
commonsense or real world information which is part of shared human knowledge but is not explicitly present in the input. We address this limitation
by having the encoders also encode background knowledge, and present two approaches for doing so. The first is by modeling the selectional restrictions verbs place on their
semantic role fillers. We use this model to encode events, and show that these event representations are useful in detecting newswire anomalies.
Our second approach towards augmenting distributional methods is to use external knowledge bases like WordNet. We compute
ontology-grounded token-level representations of words and show that they are useful in predicting prepositional phrase attachments and textual entailment.

The second part of the thesis focuses on contextual knowledge. Machine comprehension tasks require interpreting input utterances in the context of other structured
or unstructured information. This can be challenging for multiple reasons. Firstly, given some task-specific data, \textbf{retrieving} the relevant contextual knowledge from it
can be a serious problem. Secondly, even when the relevant contextual knowledge is provided, \textbf{reasoning} over it might require executing a complex series of operations
depending on the structure of the context and the compositionality of the input language. To handle reasoning over contexts, we first describe a type constrained neural semantic parsing framework for question answering (QA).
We achieve state of the art performance on \textsc{WikiTableQuestions}, a dataset with highly compositional questions over semi-structured tables.
Proposed work in this area includes application of this framework to QA in other domains with weaker supervision. To address the challenge of retrieval, we propose to build
neural network models with explicit memory components that can adaptively reason and learn to retrieve relevant context given a question.

\end{abstract}

% TODO: Uncomment this for the dissertation
% \begin{acknowledgments}
% 
% \end{acknowledgments}



\tableofcontents
\listoffigures
\listoftables

\mainmatter

%% Double space document for easy review:
%\renewcommand{\baselinestretch}{1.66}\normalsize

% The other requirements Catherine has:
%
%  - avoid large margins.  She wants the thesis to use fewer pages, 
%    especially if it requires colour printing.
%
%  - The thesis should be formatted for double-sided printing.  This
%    means that all chapters, acknowledgements, table of contents, etc.
%    should start on odd numbered (right facing) pages.
%
%  - You need to use the department standard tech report title page.  I
%    have tried to ensure that the title page here conforms to this
%    standard.
%
%  - Use a nice serif font, such as Times Roman.  Sans serif looks bad.
%
% Other than that, just make it look good...


\chapter{Introduction}
\label{chapter:introduction}
\input{chapters/introduction}
\part{Encoding Implicit Knowledge}
\chapter{Leveraging Selectional Preferences for Event Understanding}
\label{chapter:nem}
\input{chapters/modeling_events}
\chapter{Sentence Understanding with Background Knowledge from Ontologies}
\label{chapter:ontolstm}
\input{chapters/ontolstm}
\part{Reasoning over Explicit Knowledge}
\chapter{Learning Semantic Parsers over Question Answer Pairs}
\label{chapter:nnsp}
\input{chapters/neural_semantic_parsing}
\chapter{Proposed Work: Context Retrieval for Memory Networks}
\label{chapter:memnet_qa}
\input{chapters/memnet_qa}
\chapter{Summary and Timeline}
\input{chapters/conclusion}

%\appendix
%\include{appendix}

\backmatter

%\renewcommand{\baselinestretch}{1.0}\normalsize

% By default \bibsection is \chapter*, but we really want this to show
% up in the table of contents and pdf bookmarks.
\renewcommand{\bibsection}{\chapter{\bibname}}
%\newcommand{\bibpreamble}{This text goes between the ``Bibliography''
%  header and the actual list of references}
\bibliographystyle{plainnat}
\bibliography{thesis} %your bib file

\end{document}
